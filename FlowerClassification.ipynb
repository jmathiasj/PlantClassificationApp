{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FlowerClassification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeromenicholas07/FlowerIdentifier/blob/master/FlowerClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYB5oCH-ISvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytQiejtqIawr",
        "colab_type": "code",
        "outputId": "fd649a11-3bea-49e0-a9e0-578f9610f529",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdB7_gEEIb4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datadir = \"/content/drive/My Drive/Flower\"\n",
        "valdir = \"/content/drive/My Drive/Flowers_valid\"\n",
        "categories = [\"Angels Trumpet\",\"Beach Moonflower\",\"Bougainvillea\",\"Cyclamen\",\"Daisy\",\"Dandelion\",\"Foxgloves\",\"Frangipani\",\"Gladiolus\",\"Hawaiian Hibiscus\",\"Nasturtium\",\"Purple Passionflower\",\"Rose\",\"Sacred Lotus\",\"Sunflower\",\"Tulip\",\"Wallflowers\"]\n",
        "img_size = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtdjA3KgI-dd",
        "colab_type": "code",
        "outputId": "ce8fe98a-a3a2-4892-8abd-365112329468",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from keras.applications import VGG16\n",
        "#Load the VGG model\n",
        "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPSl5m11JAKT",
        "colab_type": "code",
        "outputId": "3eb3ae99-e479-4422-c5bd-62f378ddf3d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "# Freeze the layers except the last 4 layers\n",
        "for layer in vgg_conv.layers[:-4]:\n",
        "    layer.trainable = False\n",
        " \n",
        "# Check the trainable status of the individual layers\n",
        "for layer in vgg_conv.layers:\n",
        "    print(layer, layer.trainable)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<keras.engine.input_layer.InputLayer object at 0x7f47b6091390> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f4768d612e8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f4768d61198> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f4768507b00> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f47685075c0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f47684bd400> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f47684ccef0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f47684ccba8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f476847fa20> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f4768493cf8> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f4768443438> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f4768443a58> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f47683ee668> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f47684046a0> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f47683ae518> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f47683ae748> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f47683e0198> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f47683707f0> True\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f4768388f60> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiZUAxquJCZH",
        "colab_type": "code",
        "outputId": "d3cd8654-d48d-4475-a92e-deaf5c76a2e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        " \n",
        "# Create the model\n",
        "model = models.Sequential()\n",
        " \n",
        "# Add the vgg convolutional base model\n",
        "model.add(vgg_conv)\n",
        " \n",
        "# Add new layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(17, activation='softmax'))\n",
        " \n",
        "# Show a summary of the model. Check the number of trainable parameters\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 6, 6, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 18432)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              18875392  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 17)                17425     \n",
            "=================================================================\n",
            "Total params: 33,607,505\n",
            "Trainable params: 33,607,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBMhqJfvJEBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_KspexfJGDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_dir = '/content/drive/My Drive/Flower'\n",
        "validation_data_dir = '/content/drive/My Drive/Flowers_valid'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww6pz7HvJIYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=20,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2, \n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2eY2LC2JJvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C793hfnSJKnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batchsize = 100\n",
        "val_batchsize = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94yQu8cgJL0J",
        "colab_type": "code",
        "outputId": "cf4bc316-715a-431c-90c4-76dd2f4ba7d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=train_batchsize,\n",
        "        class_mode='categorical')\n",
        " \n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=val_batchsize,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2795 images belonging to 17 classes.\n",
            "Found 269 images belonging to 17 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZAurpw-JNJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrU3jy4JJeE2",
        "colab_type": "code",
        "outputId": "0f1abc4f-9771-4f8b-c025-2f15b6d97364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1108
        }
      },
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
        "      epochs=30,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
        "      verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/30\n",
            "28/27 [==============================] - 757s 27s/step - loss: 2.8791 - acc: 0.0601 - val_loss: 2.8273 - val_acc: 0.0669\n",
            "Epoch 2/30\n",
            "28/27 [==============================] - 34s 1s/step - loss: 2.8250 - acc: 0.0827 - val_loss: 2.7991 - val_acc: 0.0892\n",
            "Epoch 3/30\n",
            "28/27 [==============================] - 42s 1s/step - loss: 2.7947 - acc: 0.0973 - val_loss: 2.7467 - val_acc: 0.0706\n",
            "Epoch 4/30\n",
            "28/27 [==============================] - 44s 2s/step - loss: 2.6800 - acc: 0.1361 - val_loss: 2.9617 - val_acc: 0.1524\n",
            "Epoch 5/30\n",
            "28/27 [==============================] - 43s 2s/step - loss: 2.6255 - acc: 0.1613 - val_loss: 2.6287 - val_acc: 0.1673\n",
            "Epoch 6/30\n",
            "28/27 [==============================] - 46s 2s/step - loss: 2.3366 - acc: 0.2414 - val_loss: 2.0710 - val_acc: 0.3941\n",
            "Epoch 7/30\n",
            "28/27 [==============================] - 43s 2s/step - loss: 2.1680 - acc: 0.3319 - val_loss: 2.7440 - val_acc: 0.3086\n",
            "Epoch 8/30\n",
            "28/27 [==============================] - 45s 2s/step - loss: 1.9124 - acc: 0.4054 - val_loss: 1.6116 - val_acc: 0.4944\n",
            "Epoch 9/30\n",
            "28/27 [==============================] - 43s 2s/step - loss: 1.6720 - acc: 0.4712 - val_loss: 1.5312 - val_acc: 0.5056\n",
            "Epoch 10/30\n",
            "28/27 [==============================] - 44s 2s/step - loss: 1.5455 - acc: 0.5256 - val_loss: 1.5195 - val_acc: 0.5316\n",
            "Epoch 11/30\n",
            "28/27 [==============================] - 44s 2s/step - loss: 1.4365 - acc: 0.5525 - val_loss: 1.2580 - val_acc: 0.5874\n",
            "Epoch 12/30\n",
            "28/27 [==============================] - 44s 2s/step - loss: 1.1912 - acc: 0.6272 - val_loss: 1.3058 - val_acc: 0.5836\n",
            "Epoch 13/30\n",
            "28/27 [==============================] - 46s 2s/step - loss: 1.1266 - acc: 0.6494 - val_loss: 1.1763 - val_acc: 0.6208\n",
            "Epoch 14/30\n",
            "28/27 [==============================] - 43s 2s/step - loss: 1.0661 - acc: 0.6656 - val_loss: 1.0031 - val_acc: 0.7138\n",
            "Epoch 15/30\n",
            "28/27 [==============================] - 45s 2s/step - loss: 0.8948 - acc: 0.7080 - val_loss: 0.9598 - val_acc: 0.7063\n",
            "Epoch 16/30\n",
            "28/27 [==============================] - 43s 2s/step - loss: 0.8318 - acc: 0.7363 - val_loss: 0.9751 - val_acc: 0.7100\n",
            "Epoch 17/30\n",
            "28/27 [==============================] - 44s 2s/step - loss: 0.8220 - acc: 0.7483 - val_loss: 0.9413 - val_acc: 0.7472\n",
            "Epoch 18/30\n",
            "28/27 [==============================] - 43s 2s/step - loss: 0.7186 - acc: 0.7729 - val_loss: 0.7844 - val_acc: 0.7732\n",
            "Epoch 19/30\n",
            "28/27 [==============================] - 45s 2s/step - loss: 0.7374 - acc: 0.7661 - val_loss: 0.7298 - val_acc: 0.7546\n",
            "Epoch 20/30\n",
            "28/27 [==============================] - 45s 2s/step - loss: 0.6590 - acc: 0.7928 - val_loss: 1.0497 - val_acc: 0.6766\n",
            "Epoch 21/30\n",
            "28/27 [==============================] - 44s 2s/step - loss: 0.6036 - acc: 0.8049 - val_loss: 1.0810 - val_acc: 0.7138\n",
            "Epoch 22/30\n",
            "28/27 [==============================] - 45s 2s/step - loss: 0.5704 - acc: 0.8187 - val_loss: 0.5088 - val_acc: 0.8327\n",
            "Epoch 23/30\n",
            "28/27 [==============================] - 43s 2s/step - loss: 0.4704 - acc: 0.8587 - val_loss: 0.8706 - val_acc: 0.8141\n",
            "Epoch 24/30\n",
            "28/27 [==============================] - 45s 2s/step - loss: 0.4728 - acc: 0.8476 - val_loss: 0.5909 - val_acc: 0.8178\n",
            "Epoch 25/30\n",
            "28/27 [==============================] - 43s 2s/step - loss: 0.4862 - acc: 0.8555 - val_loss: 0.8298 - val_acc: 0.7509\n",
            "Epoch 26/30\n",
            "28/27 [==============================] - 45s 2s/step - loss: 0.4080 - acc: 0.8686 - val_loss: 0.6865 - val_acc: 0.7993\n",
            "Epoch 27/30\n",
            "28/27 [==============================] - 45s 2s/step - loss: 0.3883 - acc: 0.8820 - val_loss: 0.4561 - val_acc: 0.8625\n",
            "Epoch 28/30\n",
            "28/27 [==============================] - 45s 2s/step - loss: 0.3251 - acc: 0.8995 - val_loss: 0.4228 - val_acc: 0.8699\n",
            "Epoch 29/30\n",
            "28/27 [==============================] - 44s 2s/step - loss: 0.3715 - acc: 0.8872 - val_loss: 0.5011 - val_acc: 0.8439\n",
            "Epoch 30/30\n",
            "28/27 [==============================] - 44s 2s/step - loss: 0.3187 - acc: 0.9119 - val_loss: 0.9773 - val_acc: 0.7770\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_5XEgj0uDsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLePhT-WZlWW",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuvB_2Jbua8W",
        "colab_type": "code",
        "outputId": "638140b4-ca67-4646-9bbb-84461c9a8fb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from tensorflow.contrib import lite\n",
        "converter = lite.TFLiteConverter.from_keras_model_file( 'model.h5' ) # Your model's name\n",
        "converter.post_training_quantize=True\n",
        "model = converter.convert()\n",
        "file = open( 'q_model.tflite' , 'wb' ) \n",
        "file.write( model )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Froze 30 variables.\n",
            "INFO:tensorflow:Converted 30 variables to const ops.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33629960"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ahf_kRqJgGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-Nxo2hASufR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def keras_to_tensorflow(keras_model, output_dir, model_name,out_prefix=\"output_\", log_tensorboard=True):\n",
        "\n",
        "    if os.path.exists(output_dir) == False:\n",
        "        os.mkdir(output_dir)\n",
        "\n",
        "    out_nodes = []\n",
        "\n",
        "    for i in range(len(keras_model.outputs)):\n",
        "        out_nodes.append(out_prefix + str(i + 1))\n",
        "        tf.identity(keras_model.output[i], out_prefix + str(i + 1))\n",
        "\n",
        "    sess = K.get_session()\n",
        "\n",
        "    from tensorflow.python.framework import graph_util, graph_io\n",
        "\n",
        "    init_graph = sess.graph.as_graph_def()\n",
        "\n",
        "    main_graph = graph_util.convert_variables_to_constants(sess, init_graph, out_nodes)\n",
        "\n",
        "    graph_io.write_graph(main_graph, output_dir, name=model_name, as_text=False)\n",
        "\n",
        "    if log_tensorboard:\n",
        "        from tensorflow.python.tools import import_pb_to_tensorboard\n",
        "\n",
        "        import_pb_to_tensorboard.import_to_tensorboard(\n",
        "            os.path.join(output_dir, model_name),\n",
        "            output_dir)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJDMQFaqS51U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_dir = '/content/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fstNqSE9TEuN",
        "colab_type": "code",
        "outputId": "4b943d1a-c8e3-4990-bd09-e0aaca1b2c01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "keras_to_tensorflow(model,output_dir=output_dir,model_name=\"saved_model.pb\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Froze 30 variables.\n",
            "INFO:tensorflow:Converted 30 variables to const ops.\n",
            "Model Imported. Visualize by running: tensorboard --logdir=/content/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csaDkrZJwaob",
        "colab_type": "code",
        "outputId": "604deb0d-6e64-4601-b6f8-a16d0d55310c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "interpreter = tf.contrib.lite.Interpreter(model_path=\"model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Test model on random input data.\n",
        "input_shape = input_details[0]['shape']\n",
        "# change the following line to feed into your own data.\n",
        "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "interpreter.invoke()\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(output_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8.4829348e-12 3.5071002e-13 1.5394824e-13 9.1178454e-10 8.7332595e-03\n",
            "  1.2238419e-02 3.0457886e-10 4.8573139e-11 8.7097683e-11 2.9146777e-10\n",
            "  1.1180977e-11 9.6238639e-10 4.5035500e-09 6.6240183e-08 2.3583577e-06\n",
            "  9.7902590e-01 2.5022080e-13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUOsJyfEXf-S",
        "colab_type": "code",
        "outputId": "eac8fed4-5647-478e-e51c-bf53cc3d73ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1170
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-0a8223703d02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"converted_model.tflite\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_saved_model\u001b[0;34m(cls, saved_model_dir, input_arrays, input_shapes, output_arrays, tag_set, signature_key)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     result = _freeze_saved_model(saved_model_dir, input_arrays, input_shapes,\n\u001b[0;32m--> 342\u001b[0;31m                                  output_arrays, tag_set, signature_key)\n\u001b[0m\u001b[1;32m    343\u001b[0m     return cls(\n\u001b[1;32m    344\u001b[0m         graph_def=result[0], input_tensors=result[1], output_tensors=result[2])\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert_saved_model.py\u001b[0m in \u001b[0;36mfreeze_saved_model\u001b[0;34m(saved_model_dir, input_arrays, input_shapes, output_arrays, tag_set, signature_key)\u001b[0m\n\u001b[1;32m    252\u001b[0m   \"\"\"\n\u001b[1;32m    253\u001b[0m   \u001b[0;31m# Read SignatureDef.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m   \u001b[0mmeta_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_meta_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m   \u001b[0msignature_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_signature_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m   \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_inputs_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignature_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert_saved_model.py\u001b[0m in \u001b[0;36mget_meta_graph_def\u001b[0;34m(saved_model_dir, tag_set)\u001b[0m\n\u001b[1;32m     59\u001b[0m   \"\"\"\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_model_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(sess, tags, export_dir, import_scope, **saver_kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m   \"\"\"\n\u001b[1;32m    268\u001b[0m   \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSavedModelLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msaver_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, sess, tags, import_scope, **saver_kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m       saver, _ = self.load_graph(sess.graph, tags, import_scope,\n\u001b[0;32m--> 420\u001b[0;31m                                  **saver_kwargs)\n\u001b[0m\u001b[1;32m    421\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_init_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mload_graph\u001b[0;34m(self, graph, tags, import_scope, **saver_kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m           \u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_graph_def\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmay\u001b[0m \u001b[0mbe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \"\"\"\n\u001b[0;32m--> 347\u001b[0;31m     \u001b[0mmeta_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_meta_graph_def_from_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m       return tf_saver._import_meta_graph_with_return_elements(  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mget_meta_graph_def_from_tags\u001b[0;34m(self, tags)\u001b[0m\n\u001b[1;32m    321\u001b[0m       raise RuntimeError(\n\u001b[1;32m    322\u001b[0m           \u001b[0;34m\"MetaGraphDef associated with tags \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[]\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m           \u001b[0;34m\" could not be found in SavedModel. To inspect available tag-sets in\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m           \u001b[0;34m\" the SavedModel, please use the SavedModel CLI: `saved_model_cli`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m       )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: MetaGraphDef associated with tags {'serve'} could not be found in SavedModel. To inspect available tag-sets in the SavedModel, please use the SavedModel CLI: `saved_model_cli`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT_JIFT9rF7M",
        "colab_type": "code",
        "outputId": "c26a1ecc-82bf-462c-ce08-a6c10096022e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path=\"q_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Print input shape and type\n",
        "print(interpreter.get_input_details()[0])  # Example: [1 224 224 3]\n",
        "print(interpreter.get_input_details()[0]['dtype'])  # Example: <class 'numpy.float32'>\n",
        "\n",
        "# Print output shape and type\n",
        "print(interpreter.get_output_details()[0])  # Example: [1 1000]\n",
        "print(interpreter.get_output_details()[0]['dtype'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'name': 'vgg16_input', 'index': 51, 'shape': array([  1, 200, 200,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}\n",
            "<class 'numpy.float32'>\n",
            "{'name': 'dense_2/Softmax', 'index': 18, 'shape': array([ 1, 17], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}\n",
            "<class 'numpy.float32'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc8z7vvMi3Xl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}